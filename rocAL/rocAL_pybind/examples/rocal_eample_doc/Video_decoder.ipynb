{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ff9965",
   "metadata": {},
   "source": [
    " ## Video Pipeline Reading From Multiple Files in rocAL\n",
    "\n",
    "This example presents a simple rocAL video pipeline that loads and decodes  video data. Illustrated below how to create a pipeline, set_outputs, build, run the pipeline and enumerate over the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1a3e9",
   "metadata": {},
   "source": [
    " ## Common Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac44489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "from amd.rocal.pipeline import Pipeline\n",
    "import amd.rocal.fn as fn\n",
    "import amd.rocal.types as types\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c364e",
   "metadata": {},
   "source": [
    "## Configuring rocAL pipeline\n",
    "Configure the pipeline paramters as required by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20307afc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_path = os.path.join(os.environ['ROCAL_DATA_PATH'], \"video_and_sequence_samples\", \"labelled_videos\")\n",
    "_rocal_cpu =  False\n",
    "batch_size = 2\n",
    "display = False\n",
    "num_threads = 4\n",
    "random_seed = 1\n",
    "tensor_format = types.NCHW\n",
    "tensor_dtype = types.FLOAT\n",
    "local_rank = 1\n",
    "sequence_length=3\n",
    "n_iter=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf11975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sequence(sequence):\n",
    "    w = sequence.shape[1]\n",
    "    h = sequence.shape[0] // sequence_length\n",
    "    c = sequence.shape[2]\n",
    "    columns = 3\n",
    "    rows = (sequence_length + 1) // (columns)\n",
    "    fig = plt.figure(figsize = (32,(16 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows*columns):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c77add7-ae3e-45a4-8037-25fcf9972133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_video_gif(data_loader, n_iter, sequence_length, gif_filename):\n",
    "#     fig = plt.figure()\n",
    "#     ims = []\n",
    "\n",
    "#     for i, it in enumerate(data_loader):\n",
    "#         if i == n_iter:\n",
    "#             break\n",
    "#         for sequence in it:\n",
    "#             ims.extend(get_sequence_images(sequence, sequence_length))\n",
    "\n",
    "#     ani = animation.ArtistAnimation(fig, ims, interval=100, blit=True)\n",
    "#     ani.save(gif_filename, writer='pillow')\n",
    "\n",
    "# def get_sequence_images(sequence, sequence_length):\n",
    "#     images = []\n",
    "#     w = sequence.shape[1]\n",
    "#     h = sequence.shape[0] // sequence_length\n",
    "#     c = sequence.shape[2]\n",
    "#     columns = 3\n",
    "#     rows = (sequence_length + 1) // columns\n",
    "\n",
    "#     for j in range(sequence_length):\n",
    "#         fig = plt.figure(figsize=(w/c, h/c))\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.imshow(sequence[j])\n",
    "#         images.append([plt.imshow(sequence[j], animated=True)])\n",
    "\n",
    "#     plt.close(fig)\n",
    "#     return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076f0f5",
   "metadata": {},
   "source": [
    "## Defining and Running the Pipeline\n",
    "Creating the pipeline using video readers for reading the video data.In this pipeline we add cascaded augmentation on the decoded sequence. We enable the output for differnet augmentaion using set_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78257053-674e-4bcd-a047-bd23bf775ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCALVideoIterator(object):\n",
    "    \"\"\"\n",
    "    ROCALVideoIterator for pyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pipelines : list of amd.rocal.pipeline.Pipeline\n",
    "                List of pipelines to use\n",
    "    size : int\n",
    "           Epoch size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pipelines, tensor_layout=types.NCHW, reverse_channels=False, multiplier=None, offset=None, tensor_dtype=types.FLOAT, display=False, sequence_length=3):\n",
    "\n",
    "        try:\n",
    "            assert pipelines is not None, \"Number of provided pipelines has to be at least 1\"\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        self.loader = pipelines\n",
    "        self.tensor_format = tensor_layout\n",
    "        self.multiplier = multiplier if multiplier else [1.0, 1.0, 1.0]\n",
    "        self.offset = offset if offset else [0.0, 0.0, 0.0]\n",
    "        self.reverse_channels = reverse_channels\n",
    "        self.tensor_dtype = tensor_dtype\n",
    "        self.batch_size = self.loader._batch_size\n",
    "        self.rim = self.loader.get_remaining_images()\n",
    "        self.display = display\n",
    "        self.iter_num = 0\n",
    "        self.sequence_length = sequence_length\n",
    "        print(\"____________REMAINING IMAGES____________:\", self.rim)\n",
    "        self.output = self.dimensions = self.dtype = None\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "\n",
    "    def __next__(self):\n",
    "        if (self.loader.is_empty()):\n",
    "            raise StopIteration\n",
    "\n",
    "        if self.loader.rocal_run() != 0:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.output_tensor_list = self.loader.get_output_tensors()\n",
    "        self.iter_num += 1\n",
    "        # Copy output from buffer to numpy array\n",
    "        if self.output is None:\n",
    "            self.dimensions = self.output_tensor_list[0].dimensions()\n",
    "            self.dtype = self.output_tensor_list[0].dtype()\n",
    "            self.layout = self.output_tensor_list[0].layout()\n",
    "            self.output = np.empty(\n",
    "                (self.dimensions[0]*self.dimensions[1], self.dimensions[2], self.dimensions[3], self.dimensions[4]), dtype=self.dtype)\n",
    "        self.output_tensor_list[0].copy_data(self.output)\n",
    "        img = torch.from_numpy(self.output)\n",
    "        # Display Frames in a video sequence\n",
    "        if self.display:\n",
    "            for batch_i in range(self.batch_size):\n",
    "                draw_frames(img[batch_i], batch_i, self.iter_num, self.layout)\n",
    "        return img\n",
    "\n",
    "    def reset(self):\n",
    "        self.loader.rocal_reset_loaders()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __del__(self):\n",
    "        self.loader.rocal_release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8bc652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline has been created succesfully\n",
      "OK: OpenVX using GPU device - 1: AMD Instinct MI100 [gfx908:sramecc+:xnack-] with 120 CUs on PCI bus 43:00.0\n",
      "\n",
      "OK: loaded 116 kernels from libvx_rpp.so\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(batch_size=batch_size, num_threads=num_threads,device_id=local_rank, seed=random_seed, rocal_cpu=_rocal_cpu,\n",
    "                    mean=[0.485 * 255, 0.456 * 255, 0.406 * 255], std=[0.229 * 255, 0.224 * 255, 0.225 * 255], tensor_layout=tensor_format, tensor_dtype=tensor_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c943d",
   "metadata": {},
   "source": [
    "## Video Pipeline\n",
    "Here we use the video reader to read the video data. Then the decoded sequences is passed to CMN.We enable the output for CMN using set_output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09691217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " check in rocalOpticalFlow rocal_api_Augmentation\n",
      " check in rocalOpticalFlowToColor rocal_api_Augmentation"
     ]
    }
   ],
   "source": [
    "with pipe:\n",
    "        images = fn.readers.video(file_root=video_path, sequence_length=3,\n",
    "                              random_shuffle=False, image_type=types.RGB)\n",
    "        optical_image = fn.optical_flow(images)\n",
    "        output_image = fn.optical_flow_to_color(optical_image)\n",
    "        pipe.set_outputs(output_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c42aa",
   "metadata": {},
   "source": [
    "## Building the Pipeline\n",
    "Here we are creating the pipeline. In order to use our Pipeline, we need to build it. This is achieved by calling the build function. Then iterator object is created with ROCALVideoIterator(video_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "974e212e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<amd.rocal.pipeline.Pipeline at 0x7f15ee7d1490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the pipeline\n",
    "pipe.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20fbd7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________REMAINING IMAGES____________: 696\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "data_loader = ROCALVideoIterator(\n",
    "    pipe, multiplier=pipe._multiplier, offset=pipe._offset,display=display,sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8309c7",
   "metadata": {},
   "source": [
    "## Visualizing outputs\n",
    "We have plotted the output of the video sequence using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3630f87f-78ff-46a0-b3ef-05c390471d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_points(images, points):\n",
    "#     assert(len(points) == len(images))\n",
    "#     for frame_points, image in zip(points, images):\n",
    "#         draw = ImageDraw.Draw(image)\n",
    "#         for x, y in frame_points:\n",
    "#             draw.ellipse((x - 3, y - 3, x + 3, y + 3), fill=\"blue\", outline=\"blue\")\n",
    "\n",
    "# def display_video(batch, duration=50, points=None):\n",
    "#     images = [Image.fromarray(frame) for sequence in batch for frame in np.array(sequence)]\n",
    "#     if points is not None:\n",
    "#         points = [frame_points for sequence in points for frame_points in np.array(sequence)]\n",
    "#         draw_points(images, points)\n",
    "#     image, *images = images\n",
    "#     with io.BytesIO() as file:\n",
    "#         image.save(file, save_all=True, append_images=images,\n",
    "#                    duration=duration, loop=0, format=\"webp\",\n",
    "#                    minimize_size=True)\n",
    "#         display.display(display.Image(data=file.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ace2cab-977e-4289-abda-661b877a13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_video(video.as_cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c1c7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "import imageio\n",
    "from PIL import Image\n",
    "frames = []\n",
    "for i, it in enumerate(data_loader):\n",
    "    # print(it.shape)\n",
    "    if i <= 6:\n",
    "        # break\n",
    "        for sequence in it:\n",
    "            # print(type(sequence), i)\n",
    "            # sequence = sequence.permute(2, 0, 1)\n",
    "            sequences = sequence.numpy()\n",
    "            pil_frame = Image.fromarray(sequences.astype('uint8'))\n",
    "            frames.append(pil_frame)\n",
    "    else:\n",
    "        output_path = 'output.gif'\n",
    "        frames[0].save(output_path, save_all=True, append_images=frames[1:], loop=0, duration=1)  # Adjust duration as needed\n",
    "        break\n",
    "    \n",
    "        # display_sequence(sequence)\n",
    "data_loader.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51da371a-c7af-4e0d-b160-b31918dd10b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"output.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"output.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ff2f9-2452-494c-b5b3-f297c53864a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b8bd0b-730e-4e0d-8f9b-49789610a603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28b1da-dec5-44c4-ba2f-4ea7d9397c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91ec85-984b-4751-a12b-7ad110b663e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e2d9c-a1bf-4646-a30e-37ed149dae17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2861b-cd37-42fc-940c-66ebd8a1867a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
