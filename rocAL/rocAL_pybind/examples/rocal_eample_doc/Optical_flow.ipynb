{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ff9965",
   "metadata": {},
   "source": [
    " ## Optical Flow in rocAL\n",
    "\n",
    "This example presents a rocAL video pipeline that loads calculate the optical flow for a given sequence of Frames. Illustrated below how to create a pipeline, set_outputs, build, run the pipeline and enumerate over the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1a3e9",
   "metadata": {},
   "source": [
    " ## Common Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac44489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "from amd.rocal.pipeline import Pipeline\n",
    "import amd.rocal.fn as fn\n",
    "import amd.rocal.types as types\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.animation as animation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c364e",
   "metadata": {},
   "source": [
    "## Configuring rocAL pipeline\n",
    "Configure the pipeline paramters as required by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20307afc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_path = \"/dockerx/ak_optical_flow/labelled_video/\"\n",
    "_rocal_cpu =  False\n",
    "batch_size = 10\n",
    "display = False\n",
    "num_threads = 1\n",
    "random_seed = 1\n",
    "tensor_format = types.NFHWC \n",
    "tensor_dtype = types.FLOAT\n",
    "local_rank = 0\n",
    "sequence_length=2\n",
    "n_iter=6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076f0f5",
   "metadata": {},
   "source": [
    "## Defining and Running the Pipeline\n",
    "Creating the pipeline using video readers for reading the video data.In this pipeline we add cascaded augmentation on the decoded sequence. We enable the output for differnet augmentaion using set_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78257053-674e-4bcd-a047-bd23bf775ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCALVideoIterator(object):\n",
    "    \"\"\"\n",
    "    ROCALVideoIterator for pyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pipelines : list of amd.rocal.pipeline.Pipeline\n",
    "                List of pipelines to use\n",
    "    size : int\n",
    "           Epoch size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pipelines, tensor_layout=types.NCHW, reverse_channels=False, multiplier=None, offset=None, tensor_dtype=types.FLOAT, display=False, sequence_length=3):\n",
    "\n",
    "        try:\n",
    "            assert pipelines is not None, \"Number of provided pipelines has to be at least 1\"\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        self.loader = pipelines\n",
    "        self.tensor_format = tensor_layout\n",
    "        self.multiplier = multiplier if multiplier else [1.0, 1.0, 1.0]\n",
    "        self.offset = offset if offset else [0.0, 0.0, 0.0]\n",
    "        self.reverse_channels = reverse_channels\n",
    "        self.tensor_dtype = tensor_dtype\n",
    "        self.batch_size = self.loader._batch_size\n",
    "        self.rim = self.loader.get_remaining_images()\n",
    "        self.display = display\n",
    "        self.iter_num = 0\n",
    "        self.sequence_length = sequence_length\n",
    "        print(\"____________REMAINING IMAGES____________:\", self.rim)\n",
    "        self.output = self.dimensions = self.dtype = None\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "\n",
    "    def __next__(self):\n",
    "        if (self.loader.is_empty()):\n",
    "            raise StopIteration\n",
    "\n",
    "        if self.loader.rocal_run() != 0:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.output_tensor_list = self.loader.get_output_tensors()\n",
    "        self.iter_num += 1\n",
    "        # Copy output from buffer to numpy array\n",
    "        if self.output is None:\n",
    "            self.dimensions = self.output_tensor_list[0].dimensions()\n",
    "            self.dtype = self.output_tensor_list[0].dtype()\n",
    "            self.layout = self.output_tensor_list[0].layout()\n",
    "            self.output = np.empty(\n",
    "                (self.dimensions[0]*self.dimensions[1], self.dimensions[2], self.dimensions[3], self.dimensions[4]), dtype=self.dtype)\n",
    "        self.output_tensor_list[0].copy_data(self.output)\n",
    "        img = torch.from_numpy(self.output)\n",
    "        # Display Frames in a video sequence\n",
    "        if self.display:\n",
    "            for batch_i in range(self.batch_size):\n",
    "                draw_frames(img[batch_i], batch_i, self.iter_num, self.layout)\n",
    "        return img\n",
    "\n",
    "    def reset(self):\n",
    "        self.loader.rocal_reset_loaders()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __del__(self):\n",
    "        self.loader.rocal_release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a8bc652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: OpenVX using GPU device - 0: AMD Instinct MI100 [gfx908:sramecc+:xnack-] with 120 CUs on PCI bus 63:00.0\n",
      "\n",
      "Pipeline has been created succesfully\n",
      "OK: loaded 116 kernels from libvx_rpp.so\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(batch_size=batch_size, num_threads=num_threads, device_id=local_rank, seed=random_seed, rocal_cpu=_rocal_cpu,\n",
    "                    tensor_layout=tensor_format, tensor_dtype=tensor_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c943d",
   "metadata": {},
   "source": [
    "## Video Pipeline\n",
    "Here we use the video reader to read the video data. Then the decoded sequences is passed to optical_flow and optical_flow_to_color.We enable the output for optical_flow_to_color using set_output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09691217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " check in rocalOpticalFlow rocal_api_Augmentation\n",
      " check in rocalOpticalFlowToColor rocal_api_Augmentation"
     ]
    }
   ],
   "source": [
    "with pipe:\n",
    "        images = fn.readers.video(file_root=video_path, sequence_length=sequence_length,\n",
    "                              random_shuffle=False, image_type=types.RGB)\n",
    "        optical_image = fn.optical_flow(images)\n",
    "        output_images = fn.optical_flow_to_color(optical_image)\n",
    "        pipe.set_outputs(output_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c42aa",
   "metadata": {},
   "source": [
    "## Building the Pipeline\n",
    "Here we are creating the pipeline. In order to use our Pipeline, we need to build it. This is achieved by calling the build function. Then iterator object is created with ROCALVideoIterator(video_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974e212e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<amd.rocal.pipeline.Pipeline at 0x7fb04edebfd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the pipeline\n",
    "pipe.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20fbd7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________REMAINING IMAGES____________: 330\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "data_loader = ROCALVideoIterator(\n",
    "    pipe, multiplier=pipe._multiplier, offset=pipe._offset,display=display,sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8309c7",
   "metadata": {},
   "source": [
    "## Visualizing outputs\n",
    "We have plotted the output of the video sequence using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba11a28-1f6b-483f-880b-beefd9966970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sequence(sequence):\n",
    "    w = sequence.shape[1]\n",
    "    h = sequence.shape[0] // sequence_length\n",
    "    c = sequence.shape[2]\n",
    "    columns = 3\n",
    "    rows = (sequence_length + 1) // (columns)\n",
    "    fig = plt.figure(figsize = (32,(16 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows*columns):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c1c7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "import imageio\n",
    "from PIL import Image\n",
    "frames = []\n",
    "for i, it in enumerate(data_loader):\n",
    "    # print(it.shape)\n",
    "    if i <= 6:\n",
    "        for sequence in it:\n",
    "            sequences = sequence.numpy()\n",
    "            pil_frame = Image.fromarray(sequences.astype('uint8'))\n",
    "            frames.append(pil_frame)\n",
    "    # else:\n",
    "output_path = 'output.gif'\n",
    "frames[0].save(output_path, save_all=True, append_images=frames[1:], loop=0, duration=1)  # Adjust duration as needed\n",
    "# break\n",
    "data_loader.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560949c",
   "metadata": {},
   "source": [
    "<!-- ![Image Alt Text](output.gif) -->\n",
    "![SegmentLocal](output.gif \"segment\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
